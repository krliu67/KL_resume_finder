{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d091084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyMuPDF\n",
      "  Downloading pymupdf-1.26.4-cp39-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Downloading pymupdf-1.26.4-cp39-abi3-win_amd64.whl (18.7 MB)\n",
      "   ---------------------------------------- 0.0/18.7 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 6.0/18.7 MB 33.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 12.8/18.7 MB 32.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.7/18.7 MB 32.8 MB/s  0:00:00\n",
      "Installing collected packages: PyMuPDF\n",
      "Successfully installed PyMuPDF-1.26.4\n"
     ]
    }
   ],
   "source": [
    "!pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "370aef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # Import the PyMuPDF library, aliased as fitz\n",
    "import re    # Import the regular expression module\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts all text from a given PDF file.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): The file path to the PDF document.\n",
    "        \n",
    "    Returns:\n",
    "        str: The extracted text, with multi-line breaks condensed.\n",
    "             Returns an error message if an exception occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the specified PDF file\n",
    "        doc = fitz.open(pdf_path)\n",
    "        text = \"\"\n",
    "        # Iterate through each page of the document\n",
    "        for page in doc:\n",
    "            # page.get_text(\"text\") ensures only plain text is extracted\n",
    "            text += page.get_text(\"text\")\n",
    "        \n",
    "        # Replace multiple consecutive newlines with a single one for easier processing\n",
    "        text = re.sub(r'\\n+', '\\n', text)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        # Return an error message if reading the PDF fails\n",
    "        return f\"Error reading PDF file: {e}\"\n",
    "\n",
    "def find_specific_experience(resume_text, keyword):\n",
    "    \"\"\"\n",
    "    Finds the specific sentences in the resume text that contain a keyword.\n",
    "    \n",
    "    Args:\n",
    "        resume_text (str): The full text of the resume.\n",
    "        keyword (str): The skill or experience to search for.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of sentences that contain the keyword.\n",
    "    \"\"\"\n",
    "    # Split the text into sentences using a regular expression.\n",
    "    # This pattern splits the text after a period, question mark, or exclamation mark\n",
    "    # that is followed by whitespace. The (?<=[.?!]) is a positive lookbehind\n",
    "    # that keeps the delimiter (.?!) as part of the sentence.\n",
    "    sentences = re.split(r'(?<=[.?!])\\s+', resume_text)\n",
    "    \n",
    "    found_sentences = []\n",
    "    \n",
    "    # Compile a regular expression to match the keyword as a whole word, case-insensitively.\n",
    "    # '\\b' is a word boundary, preventing partial matches (e.g., finding \"Java\" in \"JavaScript\").\n",
    "    keyword_regex = re.compile(r'\\b' + re.escape(keyword) + r'\\b', re.IGNORECASE)\n",
    "    \n",
    "    # Iterate over each sentence found in the text\n",
    "    for sentence in sentences:\n",
    "        # Clean up the sentence by replacing newlines with spaces and removing leading/trailing whitespace.\n",
    "        cleaned_sentence = sentence.replace('\\n', ' ').strip()\n",
    "        # Check if the cleaned sentence is not empty and contains the keyword\n",
    "        if cleaned_sentence and keyword_regex.search(cleaned_sentence):\n",
    "            # If a match is found, add the cleaned sentence to our results list\n",
    "            found_sentences.append(cleaned_sentence)\n",
    "            \n",
    "    return found_sentences\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    The main function to execute the resume analyzer.\n",
    "    \"\"\"\n",
    "    # Prompt the user to enter the name of their resume PDF file\n",
    "    pdf_file_path = input(\"Please enter the PDF filename of your resume (e.g., my_resume.pdf): \")\n",
    "    \n",
    "    # Extract the text content from the PDF\n",
    "    resume_text = extract_text_from_pdf(pdf_file_path)\n",
    "    \n",
    "    # Check if text extraction resulted in an error\n",
    "    if \"Error\" in resume_text:\n",
    "        print(resume_text)\n",
    "        return\n",
    "        \n",
    "    print(\"\\nResume content has been successfully read!\")\n",
    "    \n",
    "    # Start a loop to allow the user to perform multiple searches\n",
    "    while True:\n",
    "        # Prompt the user to enter a keyword for searching\n",
    "        search_keyword = input(\"\\nPlease enter the skill or experience you want to search for (type 'quit' to exit): \")\n",
    "        \n",
    "        # Allow the user to exit the loop\n",
    "        if search_keyword.lower() == 'quit':\n",
    "            break\n",
    "            \n",
    "        # Call the function to find all sentences containing the keyword\n",
    "        experiences = find_specific_experience(resume_text, search_keyword)\n",
    "        \n",
    "        # Check if any matching sentences were found\n",
    "        if experiences:\n",
    "            print(f\"\\n--- Found {len(experiences)} relevant experiences for '{search_keyword}' ---\")\n",
    "            # Iterate through the found sentences and print each one\n",
    "            for i, exp in enumerate(experiences, 1):\n",
    "                print(f\"\\nExperience {i}: {exp}\")\n",
    "            print(\"\\n-----------------------------------------\")\n",
    "        else:\n",
    "            # Inform the user if the keyword was not found\n",
    "            print(f\"\\nNo experiences related to '{search_keyword}' were found in your resume.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4cbc188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resume content has been successfully read!\n",
      "\n",
      "--- Found 1 relevant experiences for 'SQL' ---\n",
      "\n",
      "Experience 1: in Information and Computing Science, Ningbo University of Technology Key Courses: Data Structures and Algorithms, Database in SQL, Object-Oriented Programming, Data Visualization with Python, Mathematical Modeling, Big Data in Spark Projects Apr 2025 National Survey Design of Undergraduate Students ○Designed and executed a dual-frame survey strategy (USPS ABS + online panel) to be representative to U.S.\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "--- Found 4 relevant experiences for 'Python' ---\n",
      "\n",
      "Experience 1: Expertise in R (tidyverse, data.table), Python (pandas, scikit-learn), Machine Learning, Statistical Modeling, Causal Inference, and Data Visualization.\n",
      "\n",
      "Experience 2: Experience May 2025 - Present Research Assistant, Department of Epidemiology and Biostatistics at UMD ○Web scraping All of US datasets by searching, extracting, and filtering biomarkers in Python.\n",
      "\n",
      "Experience 3: Built image preprocessing pipelines in Python (e.g., grayscale conversion, bounding box filtering), improving feature extraction accuracy by 18%.\n",
      "\n",
      "Experience 4: in Information and Computing Science, Ningbo University of Technology Key Courses: Data Structures and Algorithms, Database in SQL, Object-Oriented Programming, Data Visualization with Python, Mathematical Modeling, Big Data in Spark Projects Apr 2025 National Survey Design of Undergraduate Students ○Designed and executed a dual-frame survey strategy (USPS ABS + online panel) to be representative to U.S.\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "--- Found 3 relevant experiences for 'R' ---\n",
      "\n",
      "Experience 1: Expertise in R (tidyverse, data.table), Python (pandas, scikit-learn), Machine Learning, Statistical Modeling, Causal Inference, and Data Visualization.\n",
      "\n",
      "Experience 2: Auto data cleaning, summary statistics, and visualizations across 30+ variables using R.\n",
      "\n",
      "Experience 3: in Survey and Data Science, University of Maryland College Park Key Courses: Machine Learning, Statistical Modeling, Data Collection, Applied Sampling, Multiple Imputation, Web Scraping in R, Inference, Modern workflow for Data Science Aug 2019 - May 2023 B.S.\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "--- Found 1 relevant experiences for 'Propensity score' ---\n",
      "\n",
      "Experience 1: Dec 2023 - Present Research Assistant, Joint Program in Survey Methodology at UMD ○Co-authored a forthcoming paper: \"Gradient-Boosted Pseudo-Weighting: Methods for Population Inference from Nonprobability Samples\", where we developed two Propensity Score methods integrating Gradient Boosting Machines for selection bias correction in nonprobability samples.\n",
      "\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ff5fd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.7-cp310-cp310-win_amd64.whl.metadata (28 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.13-cp310-cp310-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.11-cp310-cp310-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.10-cp310-cp310-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.6-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.1-cp310-cp310-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.17.3-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\suds\\research\\al\\.venv\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in d:\\suds\\research\\al\\.venv\\lib\\site-packages (from spacy) (2.2.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\suds\\research\\al\\.venv\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: jinja2 in d:\\suds\\research\\al\\.venv\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in d:\\suds\\research\\al\\.venv\\lib\\site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\suds\\research\\al\\.venv\\lib\\site-packages (from spacy) (25.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading pydantic_core-2.33.2-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in d:\\suds\\research\\al\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\suds\\research\\al\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\suds\\research\\al\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\suds\\research\\al\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\suds\\research\\al\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.3.0-cp310-cp310-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in d:\\suds\\research\\al\\.venv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\suds\\research\\al\\.venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.22.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading smart_open-7.3.0.post1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading wrapt-1.17.3-cp310-cp310-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.3.1-cp310-cp310-win_amd64.whl.metadata (10 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\suds\\research\\al\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\suds\\research\\al\\.venv\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Downloading spacy-3.8.7-cp310-cp310-win_amd64.whl (14.9 MB)\n",
      "   ---------------------------------------- 0.0/14.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 2.1/14.9 MB 10.7 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.0/14.9 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.5/14.9 MB 18.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.9/14.9 MB 20.4 MB/s  0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp310-cp310-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.13-cp310-cp310-win_amd64.whl (24 kB)\n",
      "Downloading preshed-3.0.10-cp310-cp310-win_amd64.whl (117 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 36.0 MB/s  0:00:00\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp310-cp310-win_amd64.whl (632 kB)\n",
      "   ---------------------------------------- 0.0/632.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 632.3/632.3 kB 24.7 MB/s  0:00:00\n",
      "Downloading thinc-8.3.6-cp310-cp310-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 32.2 MB/s  0:00:00\n",
      "Downloading blis-1.3.0-cp310-cp310-win_amd64.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.2/6.2 MB 34.8 MB/s  0:00:00\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading typer-0.17.3-py3-none-any.whl (46 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading cloudpathlib-0.22.0-py3-none-any.whl (61 kB)\n",
      "Downloading smart_open-7.3.0.post1-py3-none-any.whl (61 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "   ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.4/5.4 MB 32.6 MB/s  0:00:00\n",
      "Downloading marisa_trie-1.3.1-cp310-cp310-win_amd64.whl (143 kB)\n",
      "Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading wrapt-1.17.3-cp310-cp310-win_amd64.whl (38 kB)\n",
      "Installing collected packages: cymem, wrapt, wasabi, typing-inspection, spacy-loggers, spacy-legacy, shellingham, pydantic-core, murmurhash, mdurl, marisa-trie, cloudpathlib, catalogue, blis, annotated-types, srsly, smart-open, pydantic, preshed, markdown-it-py, language-data, rich, langcodes, confection, typer, thinc, weasel, spacy\n",
      "\n",
      "   - --------------------------------------  1/28 [wrapt]\n",
      "   -- -------------------------------------  2/28 [wasabi]\n",
      "   ---- -----------------------------------  3/28 [typing-inspection]\n",
      "   ----- ----------------------------------  4/28 [spacy-loggers]\n",
      "   ------- --------------------------------  5/28 [spacy-legacy]\n",
      "   ------- --------------------------------  5/28 [spacy-legacy]\n",
      "   -------- -------------------------------  6/28 [shellingham]\n",
      "   ---------- -----------------------------  7/28 [pydantic-core]\n",
      "   ------------ ---------------------------  9/28 [mdurl]\n",
      "   --------------- ------------------------ 11/28 [cloudpathlib]\n",
      "   --------------- ------------------------ 11/28 [cloudpathlib]\n",
      "   --------------- ------------------------ 11/28 [cloudpathlib]\n",
      "   ----------------- ---------------------- 12/28 [catalogue]\n",
      "   ------------------ --------------------- 13/28 [blis]\n",
      "   --------------------- ------------------ 15/28 [srsly]\n",
      "   --------------------- ------------------ 15/28 [srsly]\n",
      "   --------------------- ------------------ 15/28 [srsly]\n",
      "   --------------------- ------------------ 15/28 [srsly]\n",
      "   --------------------- ------------------ 15/28 [srsly]\n",
      "   --------------------- ------------------ 15/28 [srsly]\n",
      "   --------------------- ------------------ 15/28 [srsly]\n",
      "   --------------------- ------------------ 15/28 [srsly]\n",
      "   --------------------- ------------------ 15/28 [srsly]\n",
      "   --------------------- ------------------ 15/28 [srsly]\n",
      "   --------------------- ------------------ 15/28 [srsly]\n",
      "   --------------------- ------------------ 15/28 [srsly]\n",
      "   --------------------- ------------------ 15/28 [srsly]\n",
      "   --------------------- ------------------ 15/28 [srsly]\n",
      "   --------------------- ------------------ 15/28 [srsly]\n",
      "   ---------------------- ----------------- 16/28 [smart-open]\n",
      "   ---------------------- ----------------- 16/28 [smart-open]\n",
      "   ---------------------- ----------------- 16/28 [smart-open]\n",
      "   ------------------------ --------------- 17/28 [pydantic]\n",
      "   ------------------------ --------------- 17/28 [pydantic]\n",
      "   ------------------------ --------------- 17/28 [pydantic]\n",
      "   ------------------------ --------------- 17/28 [pydantic]\n",
      "   ------------------------ --------------- 17/28 [pydantic]\n",
      "   ------------------------ --------------- 17/28 [pydantic]\n",
      "   ------------------------ --------------- 17/28 [pydantic]\n",
      "   ------------------------ --------------- 17/28 [pydantic]\n",
      "   ------------------------ --------------- 17/28 [pydantic]\n",
      "   ------------------------ --------------- 17/28 [pydantic]\n",
      "   ------------------------ --------------- 17/28 [pydantic]\n",
      "   ------------------------ --------------- 17/28 [pydantic]\n",
      "   ------------------------ --------------- 17/28 [pydantic]\n",
      "   ------------------------ --------------- 17/28 [pydantic]\n",
      "   ------------------------ --------------- 17/28 [pydantic]\n",
      "   ------------------------- -------------- 18/28 [preshed]\n",
      "   --------------------------- ------------ 19/28 [markdown-it-py]\n",
      "   --------------------------- ------------ 19/28 [markdown-it-py]\n",
      "   --------------------------- ------------ 19/28 [markdown-it-py]\n",
      "   --------------------------- ------------ 19/28 [markdown-it-py]\n",
      "   --------------------------- ------------ 19/28 [markdown-it-py]\n",
      "   --------------------------- ------------ 19/28 [markdown-it-py]\n",
      "   --------------------------- ------------ 19/28 [markdown-it-py]\n",
      "   --------------------------- ------------ 19/28 [markdown-it-py]\n",
      "   ---------------------------- ----------- 20/28 [language-data]\n",
      "   ---------------------------- ----------- 20/28 [language-data]\n",
      "   ---------------------------- ----------- 20/28 [language-data]\n",
      "   ---------------------------- ----------- 20/28 [language-data]\n",
      "   ---------------------------- ----------- 20/28 [language-data]\n",
      "   ------------------------------ --------- 21/28 [rich]\n",
      "   ------------------------------ --------- 21/28 [rich]\n",
      "   ------------------------------ --------- 21/28 [rich]\n",
      "   ------------------------------ --------- 21/28 [rich]\n",
      "   ------------------------------ --------- 21/28 [rich]\n",
      "   ------------------------------ --------- 21/28 [rich]\n",
      "   ------------------------------ --------- 21/28 [rich]\n",
      "   ------------------------------ --------- 21/28 [rich]\n",
      "   ------------------------------ --------- 21/28 [rich]\n",
      "   ------------------------------ --------- 21/28 [rich]\n",
      "   ------------------------------- -------- 22/28 [langcodes]\n",
      "   ------------------------------- -------- 22/28 [langcodes]\n",
      "   -------------------------------- ------- 23/28 [confection]\n",
      "   ---------------------------------- ----- 24/28 [typer]\n",
      "   ---------------------------------- ----- 24/28 [typer]\n",
      "   ---------------------------------- ----- 24/28 [typer]\n",
      "   ----------------------------------- ---- 25/28 [thinc]\n",
      "   ----------------------------------- ---- 25/28 [thinc]\n",
      "   ----------------------------------- ---- 25/28 [thinc]\n",
      "   ----------------------------------- ---- 25/28 [thinc]\n",
      "   ----------------------------------- ---- 25/28 [thinc]\n",
      "   ----------------------------------- ---- 25/28 [thinc]\n",
      "   ----------------------------------- ---- 25/28 [thinc]\n",
      "   ----------------------------------- ---- 25/28 [thinc]\n",
      "   ----------------------------------- ---- 25/28 [thinc]\n",
      "   ----------------------------------- ---- 25/28 [thinc]\n",
      "   ----------------------------------- ---- 25/28 [thinc]\n",
      "   ----------------------------------- ---- 25/28 [thinc]\n",
      "   ----------------------------------- ---- 25/28 [thinc]\n",
      "   ----------------------------------- ---- 25/28 [thinc]\n",
      "   ----------------------------------- ---- 25/28 [thinc]\n",
      "   ----------------------------------- ---- 25/28 [thinc]\n",
      "   ------------------------------------- -- 26/28 [weasel]\n",
      "   ------------------------------------- -- 26/28 [weasel]\n",
      "   ------------------------------------- -- 26/28 [weasel]\n",
      "   ------------------------------------- -- 26/28 [weasel]\n",
      "   ------------------------------------- -- 26/28 [weasel]\n",
      "   ------------------------------------- -- 26/28 [weasel]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   -------------------------------------- - 27/28 [spacy]\n",
      "   ---------------------------------------- 28/28 [spacy]\n",
      "\n",
      "Successfully installed annotated-types-0.7.0 blis-1.3.0 catalogue-2.0.10 cloudpathlib-0.22.0 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.3.1 markdown-it-py-4.0.0 mdurl-0.1.2 murmurhash-1.0.13 preshed-3.0.10 pydantic-2.11.7 pydantic-core-2.33.2 rich-14.1.0 shellingham-1.5.4 smart-open-7.3.0.post1 spacy-3.8.7 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.6 typer-0.17.3 typing-inspection-0.4.1 wasabi-1.1.3 weasel-0.4.1 wrapt-1.17.3\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
